{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Device & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoImageProcessor\n",
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 5216/5216 [00:00<00:00, 16915.47it/s]\n",
      "Resolving data files: 100%|██████████| 624/624 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = load_dataset(\"imagefolder\", data_dir=\"./datasets/chest_xray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 5216\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 16\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 624\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(raw_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "labels = labels = raw_dataset[\"train\"].features[\"label\"].names\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id, id2label = dict(), dict()\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "  label2id[i] = label\n",
    "  id2label[label] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'NORMAL', 1: 'PNEUMONIA'}\n",
      "{'NORMAL': 0, 'PNEUMONIA': 1}\n"
     ]
    }
   ],
   "source": [
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    "resizer = RandomResizedCrop(size)\n",
    "normalize = Normalize(image_processor.image_mean, image_processor.image_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_transforms = Compose([resizer, ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "  examples[\"image\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "  # del examples[\"image\"]\n",
    "  return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raw_dataset.with_transform(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 5216\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 16\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 624\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing metrics for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "  predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "  return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82770"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from own_model import AutoCompositeModel\n",
    "from training_own import get_model_params\n",
    "\n",
    "PATH = './model_20231222_111631_1'\n",
    "\n",
    "model = AutoCompositeModel()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "# saved\n",
    "get_model_params(model.my_new_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = torch.utils.data.DataLoader(dataset['train'], batch_size=16, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset['test'], batch_size=16, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset['test'], batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.my_new_layers.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "accuracy_metric = Accuracy(task='multiclass', num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_own import train_one_epoch, train_many_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "N_EXAMPLES = 25\n",
    "\n",
    "cum_error = 0\n",
    "\n",
    "testing_fragment = dataset['test'].shuffle(seed=1)[:N_EXAMPLES]\n",
    "inputs = testing_fragment['image']\n",
    "labels_true = testing_fragment['label']\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "  input = inputs[i]\n",
    "  label_true = labels_true[i]\n",
    "  logits = model(input[None, ...]).detach().numpy()\n",
    "  label_pred = np.argmax(logits)\n",
    "  \n",
    "  cum_error += abs(label_pred - label_true)\n",
    "  print('index {}: true/predicted: {}/{}'.format(i, label_true, label_pred))\n",
    "  \n",
    "error = cum_error / N_EXAMPLES\n",
    "\n",
    "accuracy = 1 - error\n",
    "\n",
    "print('testing accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "train_many_epochs(\n",
    "  2,\n",
    "  model=model,\n",
    "  training_loader=training_loader,\n",
    "  validation_loader=validation_loader,\n",
    "  optimizer=optimizer,\n",
    "  loss_fn=loss_fn,\n",
    "  accuracy_metric=accuracy_metric,\n",
    "  cuda_device=device,\n",
    "  epoch_index=10,\n",
    "  logging_frequency=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "N_EXAMPLES = 50\n",
    "\n",
    "cum_error = 0\n",
    "\n",
    "testing_fragment = dataset['test'].shuffle(seed=1)[:N_EXAMPLES]\n",
    "inputs = testing_fragment['image']\n",
    "labels_true = testing_fragment['label']\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "  input = inputs[i]\n",
    "  label_true = labels_true[i]\n",
    "  logits = model(input[None, ...]).detach().numpy()\n",
    "  label_pred = np.argmax(logits)\n",
    "  \n",
    "  cum_error += abs(label_pred - label_true)\n",
    "  print('index {}: true/predicted: {}/{}'.format(i, label_true, label_pred))\n",
    "  \n",
    "error = cum_error / N_EXAMPLES\n",
    "\n",
    "accuracy = 1 - error\n",
    "\n",
    "print('testing accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "N_EXAMPLES = 50\n",
    "\n",
    "cum_error = 0\n",
    "\n",
    "testing_fragment = dataset['test'].shuffle(seed=1)[:N_EXAMPLES]\n",
    "inputs = testing_fragment['image']\n",
    "labels_true = testing_fragment['label']\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "  input = inputs[i]\n",
    "  label_true = labels_true[i]\n",
    "  logits = model(input[None, ...]).detach().numpy()\n",
    "  label_pred = np.argmax(logits)\n",
    "  \n",
    "  cum_error += abs(label_pred - label_true)\n",
    "  print('index {}: true/predicted: {}/{}'.format(i, label_true, label_pred))\n",
    "  \n",
    "error = cum_error / N_EXAMPLES\n",
    "\n",
    "accuracy = 1 - error\n",
    "\n",
    "print('testing accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
