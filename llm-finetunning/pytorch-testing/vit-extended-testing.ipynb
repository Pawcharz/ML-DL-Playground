{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Device & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoImageProcessor\n",
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 5216/5216 [00:00<00:00, 17267.70it/s]\n",
      "Resolving data files: 100%|██████████| 624/624 [00:00<00:00, 208114.32it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = load_dataset(\"imagefolder\", data_dir=\"./datasets/chest_xray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 5216\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 16\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 624\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(raw_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "labels = labels = raw_dataset[\"train\"].features[\"label\"].names\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id, id2label = dict(), dict()\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "  label2id[i] = label\n",
    "  id2label[label] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'NORMAL', 1: 'PNEUMONIA'}\n",
      "{'NORMAL': 0, 'PNEUMONIA': 1}\n"
     ]
    }
   ],
   "source": [
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    "resizer = RandomResizedCrop(size)\n",
    "normalize = Normalize(image_processor.image_mean, image_processor.image_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_transforms = Compose([resizer, ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "  examples[\"image\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "  # del examples[\"image\"]\n",
    "  return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raw_dataset.with_transform(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 5216\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 16\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 624\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing metrics for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "  predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "  return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82770"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import ViTForImageClassification\n",
    "\n",
    "class MyCompositeModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MyCompositeModel, self).__init__()\n",
    "    \n",
    "    self.pretrained = ViTForImageClassification.from_pretrained(\n",
    "      \"google/vit-base-patch16-224\",\n",
    "      num_labels=1000\n",
    "    )\n",
    "    self.my_new_layers = nn.Sequential(\n",
    "      nn.LayerNorm(1000),\n",
    "      nn.Linear(1000, 64),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(64, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(128, 64),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(64, 2)\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.pretrained(x).logits\n",
    "    x = self.my_new_layers(x)\n",
    "    return x\n",
    "  \n",
    "model = MyCompositeModel()\n",
    "model = model.to(device)\n",
    "\n",
    "get_n_params(model.my_new_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = torch.utils.data.DataLoader(dataset['train'], batch_size=16, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset['test'], batch_size=16, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset['test'], batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.my_new_layers.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "accuracy_metric = Accuracy(task='multiclass', num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Epoch Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer, logging_frequency):\n",
    "  running_loss = 0.\n",
    "  running_accuracy = 0.\n",
    "  last_loss = 0.\n",
    "\n",
    "  # Here, we use enumerate(training_loader) instead of\n",
    "  # iter(training_loader) so that we can track the batch\n",
    "  # index and do some intra-epoch reporting\n",
    "  for i, data in enumerate(training_loader):\n",
    "  \n",
    "    # Every data instance is an input + label pair\n",
    "    inputs = data['image'].to(device)\n",
    "    labels = data['label'].to(device)\n",
    "  \n",
    "    # Zero your gradients for every batch!\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Make predictions for this batch\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Compute the loss and its gradients\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    loss.backward()\n",
    "    \n",
    "    training_accuracy = accuracy_metric(outputs, labels)\n",
    "\n",
    "    # Adjust learning weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Gather data and report\n",
    "    running_loss += loss.item()\n",
    "    running_accuracy += training_accuracy\n",
    "    \n",
    "    # print('batch {}', i)\n",
    "    \n",
    "    if (i+1) % logging_frequency == 0:\n",
    "      last_loss = running_loss / logging_frequency # loss per batch\n",
    "      last_accuracy = running_accuracy / logging_frequency # accuracy per batch\n",
    "      print('  batch {} loss: {} training_accuracy: {}'.format(i + 1, last_loss, last_accuracy))\n",
    "      tb_x = epoch_index * len(training_loader) + i + 1\n",
    "      tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "      running_loss = 0.\n",
    "      running_accuracy = 0.\n",
    "  \n",
    "  return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many Epochs Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many_epochs(epochs, writer, logging_frequency):\n",
    "  best_vloss = 1_000_000.\n",
    "\n",
    "  for epoch_number in range(epochs):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer, logging_frequency)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    running_vacc = 0.0\n",
    "    \n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "    \n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "      for i, vdata in enumerate(validation_loader):\n",
    "        vinputs = vdata['image'].to(device)\n",
    "        vlabels = vdata['label'].to(device)\n",
    "        voutputs = model(vinputs)\n",
    "        \n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        running_vloss += vloss\n",
    "        \n",
    "        vacc = accuracy_metric(voutputs, vlabels)\n",
    "        running_vacc += vacc\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    avg_vacc = running_vacc / (i + 1)\n",
    "    print('LOSS train {} valid {} ACCURACY validation {}'.format(avg_loss, avg_vloss, avg_vacc))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars(\n",
    "      'Training vs. Validation Loss',\n",
    "      { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "      epoch_number + 1\n",
    "    )\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "      best_vloss = avg_vloss\n",
    "      model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "      torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "sum_writer = SummaryWriter('runs/chest_trainer_{}'.format(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 50 loss: 0.6133961856365204 training_accuracy: 0.7212499976158142\n",
      "  batch 100 loss: 0.5611645984649658 training_accuracy: 0.7400000095367432\n",
      "  batch 150 loss: 0.5300955468416214 training_accuracy: 0.7524999976158142\n",
      "  batch 200 loss: 0.5244018507003784 training_accuracy: 0.7324999570846558\n",
      "  batch 250 loss: 0.49360880374908445 training_accuracy: 0.7475000023841858\n",
      "  batch 300 loss: 0.4522400680184364 training_accuracy: 0.7574999928474426\n",
      "LOSS train 0.4522400680184364 valid 0.6620761752128601 ACCURACY validation 0.629807710647583\n",
      "EPOCH 2:\n",
      "  batch 50 loss: 0.4048808237910271 training_accuracy: 0.8162499666213989\n",
      "  batch 100 loss: 0.3686318436264992 training_accuracy: 0.8424999713897705\n",
      "  batch 150 loss: 0.37294179886579515 training_accuracy: 0.8424999713897705\n",
      "  batch 200 loss: 0.3259737005829811 training_accuracy: 0.8612499833106995\n",
      "  batch 250 loss: 0.284466652572155 training_accuracy: 0.8787499666213989\n",
      "  batch 300 loss: 0.28422351971268656 training_accuracy: 0.8799999952316284\n",
      "LOSS train 0.28422351971268656 valid 0.37642812728881836 ACCURACY validation 0.8333333730697632\n"
     ]
    }
   ],
   "source": [
    "train_many_epochs(2, sum_writer, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  -  0 0\n",
      "1  -  0 0\n",
      "2  -  1 0\n",
      "3  -  0 0\n",
      "4  -  0 0\n",
      "5  -  1 0\n",
      "6  -  0 0\n",
      "7  -  0 0\n",
      "8  -  1 1\n",
      "9  -  1 1\n",
      "10  -  1 1\n",
      "11  -  1 1\n",
      "12  -  1 1\n",
      "13  -  1 1\n",
      "14  -  1 1\n",
      "15  -  1 1\n"
     ]
    }
   ],
   "source": [
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "for i, image in enumerate(raw_dataset['validation']):\n",
    "  input = dataset['validation'][i]['image']\n",
    "  label_true = dataset['validation'][i]['label']\n",
    "  logits = model(input[None, ...]).detach().numpy()\n",
    "  label_pred = np.argmax(logits)\n",
    "  print(i, \" - \" ,label_pred, label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
