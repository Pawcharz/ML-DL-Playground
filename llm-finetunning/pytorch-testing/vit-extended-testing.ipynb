{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Device & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoImageProcessor\n",
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 5216/5216 [00:00<00:00, 15691.73it/s]\n",
      "Resolving data files: 100%|██████████| 624/624 [00:00<00:00, 208230.22it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = load_dataset(\"imagefolder\", data_dir=\"./datasets/chest_xray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 5216\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 16\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 624\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(raw_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "labels = labels = raw_dataset[\"train\"].features[\"label\"].names\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id, id2label = dict(), dict()\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "  label2id[i] = label\n",
    "  id2label[label] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'NORMAL', 1: 'PNEUMONIA'}\n",
      "{'NORMAL': 0, 'PNEUMONIA': 1}\n"
     ]
    }
   ],
   "source": [
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    "resizer = RandomResizedCrop(size)\n",
    "normalize = Normalize(image_processor.image_mean, image_processor.image_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_transforms = Compose([resizer, ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "  examples[\"image\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "  # del examples[\"image\"]\n",
    "  return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raw_dataset.with_transform(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 5216\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 16\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 624\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing metrics for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "  predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "  return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82770"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import ViTForImageClassification\n",
    "\n",
    "class MyCompositeModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MyCompositeModel, self).__init__()\n",
    "    \n",
    "    self.pretrained = ViTForImageClassification.from_pretrained(\n",
    "      \"google/vit-base-patch16-224\",\n",
    "      num_labels=1000\n",
    "    )\n",
    "    self.my_new_layers = nn.Sequential(\n",
    "      nn.LayerNorm(1000),\n",
    "      nn.Linear(1000, 64),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(64, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(128, 64),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(64, 2)\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.pretrained(x).logits\n",
    "    x = self.my_new_layers(x)\n",
    "    return x\n",
    "  \n",
    "model = MyCompositeModel()\n",
    "model = model.to(device)\n",
    "\n",
    "get_n_params(model.my_new_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = torch.utils.data.DataLoader(dataset['train'], batch_size=16, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset['test'], batch_size=16, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset['test'], batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.my_new_layers.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "accuracy_metric = Accuracy(task='multiclass', num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Epoch Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer, logging_frequency):\n",
    "  running_loss = 0.\n",
    "  running_accuracy = 0.\n",
    "  last_loss = 0.\n",
    "\n",
    "  # Here, we use enumerate(training_loader) instead of\n",
    "  # iter(training_loader) so that we can track the batch\n",
    "  # index and do some intra-epoch reporting\n",
    "  for i, data in enumerate(training_loader):\n",
    "  \n",
    "    # Every data instance is an input + label pair\n",
    "    inputs = data['image'].to(device)\n",
    "    labels = data['label'].to(device)\n",
    "  \n",
    "    # Zero your gradients for every batch!\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Make predictions for this batch\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Compute the loss and its gradients\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    loss.backward()\n",
    "    \n",
    "    training_accuracy = accuracy_metric(outputs, labels)\n",
    "\n",
    "    # Adjust learning weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Gather data and report\n",
    "    running_loss += loss.item()\n",
    "    running_accuracy += training_accuracy\n",
    "    \n",
    "    # print('batch {}', i)\n",
    "    \n",
    "    if (i+1) % logging_frequency == 0:\n",
    "      last_loss = running_loss / logging_frequency # loss per batch\n",
    "      last_accuracy = running_accuracy / logging_frequency # accuracy per batch\n",
    "      print('  batch {} loss: {} training_accuracy: {}'.format(i + 1, last_loss, last_accuracy))\n",
    "      tb_x = epoch_index * len(training_loader) + i + 1\n",
    "      tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "      running_loss = 0.\n",
    "      running_accuracy = 0.\n",
    "  \n",
    "  return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many Epochs Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many_epochs(epochs, writer, logging_frequency):\n",
    "  best_vloss = 1_000_000.\n",
    "\n",
    "  for epoch_number in range(epochs):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer, logging_frequency)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    running_vacc = 0.0\n",
    "    \n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "    \n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "      for i, vdata in enumerate(validation_loader):\n",
    "        vinputs = vdata['image'].to(device)\n",
    "        vlabels = vdata['label'].to(device)\n",
    "        voutputs = model(vinputs)\n",
    "        \n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        running_vloss += vloss\n",
    "        \n",
    "        vacc = accuracy_metric(voutputs, vlabels)\n",
    "        running_vacc += vacc\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    avg_vacc = running_vacc / (i + 1)\n",
    "    print('LOSS train {} valid {} ACCURACY validation {}'.format(avg_loss, avg_vloss, avg_vacc))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars(\n",
    "      'Training vs. Validation Loss',\n",
    "      { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "      epoch_number + 1\n",
    "    )\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "      best_vloss = avg_vloss\n",
    "      model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "      torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "sum_writer = SummaryWriter('runs/chest_trainer_{}'.format(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 50 loss: 0.6328732705116272 training_accuracy: 0.7425000071525574\n",
      "  batch 100 loss: 0.5719836354255676 training_accuracy: 0.7425000071525574\n",
      "  batch 150 loss: 0.5658124047517776 training_accuracy: 0.7387499809265137\n",
      "  batch 200 loss: 0.5604046785831451 training_accuracy: 0.731249988079071\n",
      "  batch 250 loss: 0.538584772348404 training_accuracy: 0.7400000095367432\n",
      "  batch 300 loss: 0.5009221410751343 training_accuracy: 0.7674999833106995\n",
      "LOSS train 0.5009221410751343 valid 0.6239355802536011 ACCURACY validation 0.625\n",
      "EPOCH 2:\n",
      "  batch 50 loss: 0.5129212892055511 training_accuracy: 0.7137500047683716\n",
      "  batch 100 loss: 0.4810864895582199 training_accuracy: 0.7299999594688416\n",
      "  batch 150 loss: 0.44143265306949614 training_accuracy: 0.8025000095367432\n",
      "  batch 200 loss: 0.38980439096689223 training_accuracy: 0.8462499976158142\n",
      "  batch 250 loss: 0.38685330003499985 training_accuracy: 0.8424999713897705\n",
      "  batch 300 loss: 0.34139414593577383 training_accuracy: 0.85999995470047\n",
      "LOSS train 0.34139414593577383 valid 0.495215505361557 ACCURACY validation 0.7371795177459717\n"
     ]
    }
   ],
   "source": [
    "train_many_epochs(2, sum_writer, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  -  1 0\n",
      "1  -  1 0\n",
      "2  -  1 0\n",
      "3  -  1 0\n",
      "4  -  0 0\n",
      "5  -  1 0\n",
      "6  -  1 0\n",
      "7  -  1 0\n",
      "8  -  1 1\n",
      "9  -  1 1\n",
      "10  -  1 1\n",
      "11  -  1 1\n",
      "12  -  1 1\n",
      "13  -  1 1\n",
      "14  -  1 1\n",
      "15  -  1 1\n"
     ]
    }
   ],
   "source": [
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "for i, image in enumerate(raw_dataset['validation']):\n",
    "  input = dataset['validation'][i]['image']\n",
    "  label_true = dataset['validation'][i]['label']\n",
    "  logits = model(input[None, ...]).detach().numpy()\n",
    "  label_pred = np.argmax(logits)\n",
    "  print(i, \" - \" ,label_pred, label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 25 loss: 0.27799043387174605 training_accuracy: 0.8774999976158142\n",
      "  batch 50 loss: 0.28583341389894484 training_accuracy: 0.8924999833106995\n",
      "  batch 75 loss: 0.3371810042858124 training_accuracy: 0.8424999713897705\n",
      "  batch 100 loss: 0.25420293360948565 training_accuracy: 0.8949999809265137\n",
      "  batch 125 loss: 0.267878472507 training_accuracy: 0.8924999833106995\n",
      "  batch 150 loss: 0.27907154023647307 training_accuracy: 0.8849999904632568\n",
      "  batch 175 loss: 0.23940888077020644 training_accuracy: 0.8949999809265137\n",
      "  batch 200 loss: 0.3184510940313339 training_accuracy: 0.8624999523162842\n",
      "  batch 225 loss: 0.32735574573278425 training_accuracy: 0.8549999594688416\n",
      "  batch 250 loss: 0.24683617442846298 training_accuracy: 0.8849999904632568\n",
      "  batch 275 loss: 0.24874511897563933 training_accuracy: 0.8999999761581421\n",
      "  batch 300 loss: 0.275392587184906 training_accuracy: 0.8725000023841858\n",
      "  batch 325 loss: 0.2588343775272369 training_accuracy: 0.9074999690055847\n",
      "LOSS train 0.2588343775272369 valid 0.452780544757843 ACCURACY validation 0.8044871687889099\n",
      "EPOCH 2:\n",
      "  batch 25 loss: 0.1863073632121086 training_accuracy: 0.9300000071525574\n",
      "  batch 50 loss: 0.25777238607406616 training_accuracy: 0.8924999833106995\n",
      "  batch 75 loss: 0.2663338355720043 training_accuracy: 0.8849999904632568\n",
      "  batch 100 loss: 0.2840000066161156 training_accuracy: 0.8824999928474426\n",
      "  batch 125 loss: 0.27003123819828034 training_accuracy: 0.8924999833106995\n",
      "  batch 150 loss: 0.20482087910175323 training_accuracy: 0.9149999618530273\n",
      "  batch 175 loss: 0.2793748815357685 training_accuracy: 0.8700000047683716\n",
      "  batch 200 loss: 0.22130969762802125 training_accuracy: 0.9024999737739563\n",
      "  batch 225 loss: 0.23061730086803436 training_accuracy: 0.8949999809265137\n",
      "  batch 250 loss: 0.2192419797182083 training_accuracy: 0.8999999761581421\n",
      "  batch 275 loss: 0.28840032577514646 training_accuracy: 0.8774999976158142\n",
      "  batch 300 loss: 0.23549653232097625 training_accuracy: 0.9024999737739563\n",
      "  batch 325 loss: 0.21206294909119605 training_accuracy: 0.9174999594688416\n",
      "LOSS train 0.21206294909119605 valid 0.33077162504196167 ACCURACY validation 0.8589743971824646\n",
      "EPOCH 3:\n",
      "  batch 25 loss: 0.3210113152861595 training_accuracy: 0.8700000047683716\n",
      "  batch 50 loss: 0.2655200891196728 training_accuracy: 0.887499988079071\n",
      "  batch 75 loss: 0.28625273913145066 training_accuracy: 0.8675000071525574\n",
      "  batch 100 loss: 0.20663668006658553 training_accuracy: 0.9074999690055847\n",
      "  batch 125 loss: 0.28722820460796356 training_accuracy: 0.887499988079071\n",
      "  batch 150 loss: 0.2520413914322853 training_accuracy: 0.8949999809265137\n",
      "  batch 175 loss: 0.26144165217876436 training_accuracy: 0.8924999833106995\n",
      "  batch 200 loss: 0.23412174850702286 training_accuracy: 0.8974999785423279\n",
      "  batch 225 loss: 0.25376267462968827 training_accuracy: 0.8974999785423279\n",
      "  batch 250 loss: 0.21647612154483795 training_accuracy: 0.9124999642372131\n",
      "  batch 275 loss: 0.21389161497354509 training_accuracy: 0.9124999642372131\n",
      "  batch 300 loss: 0.2279078534245491 training_accuracy: 0.9124999642372131\n",
      "  batch 325 loss: 0.2638278391957283 training_accuracy: 0.8774999976158142\n",
      "LOSS train 0.2638278391957283 valid 0.2919106185436249 ACCURACY validation 0.8685897588729858\n",
      "EPOCH 4:\n",
      "  batch 25 loss: 0.24819012582302094 training_accuracy: 0.8974999785423279\n",
      "  batch 50 loss: 0.22187748223543166 training_accuracy: 0.8999999761581421\n",
      "  batch 75 loss: 0.20753796219825746 training_accuracy: 0.9149999618530273\n",
      "  batch 100 loss: 0.2548668061196804 training_accuracy: 0.8899999856948853\n",
      "  batch 125 loss: 0.2343938359618187 training_accuracy: 0.887499988079071\n",
      "  batch 150 loss: 0.22994169235229492 training_accuracy: 0.92249995470047\n",
      "  batch 175 loss: 0.23340984672307968 training_accuracy: 0.9024999737739563\n",
      "  batch 200 loss: 0.3146343728899956 training_accuracy: 0.85999995470047\n",
      "  batch 225 loss: 0.2179298508167267 training_accuracy: 0.9174999594688416\n",
      "  batch 250 loss: 0.22438066005706786 training_accuracy: 0.9174999594688416\n",
      "  batch 275 loss: 0.20458698131144046 training_accuracy: 0.9149999618530273\n",
      "  batch 300 loss: 0.24552730336785317 training_accuracy: 0.8924999833106995\n",
      "  batch 325 loss: 0.286388581097126 training_accuracy: 0.8849999904632568\n",
      "LOSS train 0.286388581097126 valid 0.3560152053833008 ACCURACY validation 0.8445512652397156\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "train_many_epochs(4, sum_writer, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0: true/predicted: 0/0\n",
      "index 1: true/predicted: 1/1\n",
      "index 2: true/predicted: 1/1\n",
      "index 3: true/predicted: 1/1\n",
      "index 4: true/predicted: 1/1\n",
      "index 5: true/predicted: 0/0\n",
      "index 6: true/predicted: 0/0\n",
      "index 7: true/predicted: 0/1\n",
      "index 8: true/predicted: 0/0\n",
      "index 9: true/predicted: 1/1\n",
      "index 10: true/predicted: 0/0\n",
      "index 11: true/predicted: 1/1\n",
      "index 12: true/predicted: 1/1\n",
      "index 13: true/predicted: 1/1\n",
      "index 14: true/predicted: 0/0\n",
      "index 15: true/predicted: 1/1\n",
      "index 16: true/predicted: 1/1\n",
      "index 17: true/predicted: 1/1\n",
      "index 18: true/predicted: 1/1\n",
      "index 19: true/predicted: 0/1\n",
      "index 20: true/predicted: 1/1\n",
      "index 21: true/predicted: 1/1\n",
      "index 22: true/predicted: 0/1\n",
      "index 23: true/predicted: 1/1\n",
      "index 24: true/predicted: 1/1\n",
      "index 25: true/predicted: 1/1\n",
      "index 26: true/predicted: 0/0\n",
      "index 27: true/predicted: 0/0\n",
      "index 28: true/predicted: 0/0\n",
      "index 29: true/predicted: 0/1\n",
      "index 30: true/predicted: 1/1\n",
      "index 31: true/predicted: 1/1\n",
      "index 32: true/predicted: 1/1\n",
      "index 33: true/predicted: 0/0\n",
      "index 34: true/predicted: 0/0\n",
      "index 35: true/predicted: 1/1\n",
      "index 36: true/predicted: 1/1\n",
      "index 37: true/predicted: 0/0\n",
      "index 38: true/predicted: 0/0\n",
      "index 39: true/predicted: 1/1\n",
      "index 40: true/predicted: 0/0\n",
      "index 41: true/predicted: 1/1\n",
      "index 42: true/predicted: 1/1\n",
      "index 43: true/predicted: 1/0\n",
      "index 44: true/predicted: 1/1\n",
      "index 45: true/predicted: 0/1\n",
      "index 46: true/predicted: 1/1\n",
      "index 47: true/predicted: 1/1\n",
      "index 48: true/predicted: 0/1\n",
      "index 49: true/predicted: 1/1\n",
      "testing accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "cum_error = 0\n",
    "\n",
    "testing_fragment = dataset['test'].shuffle(seed=1)[:50]\n",
    "inputs = testing_fragment['image']\n",
    "labels_true = testing_fragment['label']\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "  input = inputs[i]\n",
    "  label_true = labels_true[i]\n",
    "  logits = model(input[None, ...]).detach().numpy()\n",
    "  label_pred = np.argmax(logits)\n",
    "  \n",
    "  cum_error += abs(label_pred - label_true)\n",
    "  print('index {}: true/predicted: {}/{}'.format(i, label_true, label_pred))\n",
    "  \n",
    "error = cum_error / 50\n",
    "\n",
    "accuracy = 1 - error\n",
    "\n",
    "print('testing accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
