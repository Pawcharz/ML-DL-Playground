{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Getting dummy variables\n",
    "y_train_fixed = np.zeros((x_train.shape[0], 10))\n",
    "\n",
    "i = 0\n",
    "for [val] in y_train:\n",
    "  y_train_fixed[i][val] = 1\n",
    "  i += 1\n",
    "  \n",
    "y_train_fixed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "model = keras.Sequential(\n",
    "  [\n",
    "    keras.Input(shape=(32, 32, 3)),\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation=\"relu\"),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), padding='same', activation=\"relu\"),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), padding='same', activation=\"relu\"),\n",
    "    layers.Flatten(),\n",
    "    # layers.Dropout(0.5), # This layer randomly disabled some of the neurons\n",
    "    layers.Dense(num_classes, activation=\"softmax\"),\n",
    "  ]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # Training data will be split in chunks of this size that will be passed through the network at the same time\n",
    "epochs = 30 # During one epoch the model 'sees' all of the training data, with this parameter we determine how many times the model will be allowed to see them\n",
    "validation_split = 0.1 # Determines what percentage of training data will be used to validate the model after each epoch\n",
    "history = model.fit(x_train[:5000], y_train_fixed[:5000], batch_size=batch_size, epochs=epochs, validation_split=validation_split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
