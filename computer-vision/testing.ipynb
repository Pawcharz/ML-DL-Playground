{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Getting dummy variables\n",
    "y_train_fixed = np.zeros((y_train.shape[0], 10))\n",
    "y_test_fixed = np.zeros((y_test.shape[0], 10))\n",
    "\n",
    "i = 0\n",
    "for [val] in y_train:\n",
    "  y_train_fixed[i][val] = 1\n",
    "  i += 1\n",
    "  \n",
    "i = 0\n",
    "for [val] in y_test:\n",
    "  y_test_fixed[i][val] = 1\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I found such example on stackExchange:*\n",
    "\n",
    "```py\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=trainX[0,:,:,:].shape, filters=32, \n",
    "                 use_bias=True, kernel_size=(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(filters=64, use_bias=False, kernel_size=(5,5), strides=2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_classes, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 16, 16, 32)        9216      \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 8, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               262272    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 273,674\n",
      "Trainable params: 273,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "\n",
    "model = keras.Sequential(\n",
    "  [\n",
    "    keras.Input(shape=(32, 32, 3)),\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation=\"relu\"),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), use_bias=False, padding='same', strides=2, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(num_classes, activation=\"softmax\"),\n",
    "  ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "176/176 [==============================] - 15s 81ms/step - loss: 4.8832 - accuracy: 0.1327 - val_loss: 2.1678 - val_accuracy: 0.1788\n",
      "Epoch 2/25\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 2.1432 - accuracy: 0.1722 - val_loss: 1.8867 - val_accuracy: 0.2814\n",
      "Epoch 3/25\n",
      "176/176 [==============================] - 15s 88ms/step - loss: 1.9027 - accuracy: 0.2708 - val_loss: 1.6557 - val_accuracy: 0.3818\n",
      "Epoch 4/25\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 1.7475 - accuracy: 0.3401 - val_loss: 1.5809 - val_accuracy: 0.4400\n",
      "Epoch 5/25\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 1.6657 - accuracy: 0.3802 - val_loss: 1.4882 - val_accuracy: 0.4826\n",
      "Epoch 6/25\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 1.5890 - accuracy: 0.4114 - val_loss: 1.4024 - val_accuracy: 0.5164\n",
      "Epoch 7/25\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 1.5175 - accuracy: 0.4422 - val_loss: 1.3310 - val_accuracy: 0.5452\n",
      "Epoch 8/25\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 1.4551 - accuracy: 0.4674 - val_loss: 1.2730 - val_accuracy: 0.5592\n",
      "Epoch 9/25\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 1.3997 - accuracy: 0.4887 - val_loss: 1.2366 - val_accuracy: 0.5748\n",
      "Epoch 10/25\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 1.3607 - accuracy: 0.5064 - val_loss: 1.2282 - val_accuracy: 0.5916\n",
      "Epoch 11/25\n",
      "176/176 [==============================] - 15s 85ms/step - loss: 1.3349 - accuracy: 0.5155 - val_loss: 1.1654 - val_accuracy: 0.6034\n",
      "Epoch 12/25\n",
      "176/176 [==============================] - 15s 85ms/step - loss: 1.3007 - accuracy: 0.5311 - val_loss: 1.1419 - val_accuracy: 0.6064\n",
      "Epoch 13/25\n",
      "176/176 [==============================] - 15s 85ms/step - loss: 1.2627 - accuracy: 0.5489 - val_loss: 1.1280 - val_accuracy: 0.6210\n",
      "Epoch 14/25\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 1.2406 - accuracy: 0.5559 - val_loss: 1.1295 - val_accuracy: 0.6204\n",
      "Epoch 15/25\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 1.2119 - accuracy: 0.5657 - val_loss: 1.1331 - val_accuracy: 0.6124\n",
      "Epoch 16/25\n",
      "176/176 [==============================] - 16s 91ms/step - loss: 1.1836 - accuracy: 0.5788 - val_loss: 1.0805 - val_accuracy: 0.6290\n",
      "Epoch 17/25\n",
      "176/176 [==============================] - 15s 88ms/step - loss: 1.1692 - accuracy: 0.5830 - val_loss: 1.0648 - val_accuracy: 0.6342\n",
      "Epoch 18/25\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 1.1350 - accuracy: 0.5928 - val_loss: 1.0632 - val_accuracy: 0.6414\n",
      "Epoch 19/25\n",
      "176/176 [==============================] - 15s 88ms/step - loss: 1.1302 - accuracy: 0.5962 - val_loss: 1.0661 - val_accuracy: 0.6460\n",
      "Epoch 20/25\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 1.1033 - accuracy: 0.6103 - val_loss: 1.0310 - val_accuracy: 0.6504\n",
      "Epoch 21/25\n",
      "176/176 [==============================] - 15s 85ms/step - loss: 1.0866 - accuracy: 0.6169 - val_loss: 1.0600 - val_accuracy: 0.6426\n",
      "Epoch 22/25\n",
      "176/176 [==============================] - 15s 88ms/step - loss: 1.0650 - accuracy: 0.6213 - val_loss: 1.0267 - val_accuracy: 0.6460\n",
      "Epoch 23/25\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 1.0445 - accuracy: 0.6291 - val_loss: 1.0207 - val_accuracy: 0.6514\n",
      "Epoch 24/25\n",
      "176/176 [==============================] - 16s 88ms/step - loss: 1.0374 - accuracy: 0.6328 - val_loss: 1.0204 - val_accuracy: 0.6526\n",
      "Epoch 25/25\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 1.0177 - accuracy: 0.6378 - val_loss: 1.0001 - val_accuracy: 0.6670\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256 # Training data will be split in chunks of this size that will be passed through the network at the same time\n",
    "epochs = 25 # During one epoch the model 'sees' all of the training data, with this parameter we determine how many times the model will be allowed to see them\n",
    "validation_split = 0.1 # Determines what percentage of training data will be used to validate the model after each epoch\n",
    "history = model.fit(x_train, y_train_fixed, batch_size=batch_size, epochs=epochs, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "176/176 [==============================] - 14s 79ms/step - loss: 1.0001 - accuracy: 0.6438 - val_loss: 0.9946 - val_accuracy: 0.6670\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 15s 83ms/step - loss: 0.9940 - accuracy: 0.6495 - val_loss: 0.9879 - val_accuracy: 0.6666\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.9720 - accuracy: 0.6546 - val_loss: 0.9861 - val_accuracy: 0.6652\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.9601 - accuracy: 0.6604 - val_loss: 0.9776 - val_accuracy: 0.6790\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.9543 - accuracy: 0.6624 - val_loss: 0.9739 - val_accuracy: 0.6706\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.9349 - accuracy: 0.6705 - val_loss: 0.9670 - val_accuracy: 0.6710\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.9206 - accuracy: 0.6743 - val_loss: 0.9605 - val_accuracy: 0.6746\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.9074 - accuracy: 0.6764 - val_loss: 0.9719 - val_accuracy: 0.6686\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.8940 - accuracy: 0.6836 - val_loss: 0.9626 - val_accuracy: 0.6792\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.8792 - accuracy: 0.6876 - val_loss: 0.9456 - val_accuracy: 0.6800\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.8717 - accuracy: 0.6915 - val_loss: 0.9636 - val_accuracy: 0.6766\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.8617 - accuracy: 0.6932 - val_loss: 0.9747 - val_accuracy: 0.6740\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.8593 - accuracy: 0.6942 - val_loss: 0.9688 - val_accuracy: 0.6740\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.8347 - accuracy: 0.7049 - val_loss: 0.9692 - val_accuracy: 0.6744\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.8313 - accuracy: 0.7049 - val_loss: 0.9498 - val_accuracy: 0.6780\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.8175 - accuracy: 0.7096 - val_loss: 0.9448 - val_accuracy: 0.6764\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.8133 - accuracy: 0.7111 - val_loss: 0.9677 - val_accuracy: 0.6776\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.7979 - accuracy: 0.7166 - val_loss: 0.9409 - val_accuracy: 0.6926\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.7970 - accuracy: 0.7165 - val_loss: 0.9486 - val_accuracy: 0.6816\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.7813 - accuracy: 0.7220 - val_loss: 0.9540 - val_accuracy: 0.6800\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.7751 - accuracy: 0.7217 - val_loss: 0.9626 - val_accuracy: 0.6810\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.7695 - accuracy: 0.7269 - val_loss: 0.9404 - val_accuracy: 0.6890\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.7492 - accuracy: 0.7360 - val_loss: 0.9427 - val_accuracy: 0.6872\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.7504 - accuracy: 0.7336 - val_loss: 0.9265 - val_accuracy: 0.6918\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.7392 - accuracy: 0.7385 - val_loss: 0.9491 - val_accuracy: 0.6884\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.7335 - accuracy: 0.7399 - val_loss: 0.9317 - val_accuracy: 0.6980\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.7298 - accuracy: 0.7415 - val_loss: 0.9461 - val_accuracy: 0.6914\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.7099 - accuracy: 0.7466 - val_loss: 0.9409 - val_accuracy: 0.6938\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.7088 - accuracy: 0.7482 - val_loss: 0.9497 - val_accuracy: 0.6922\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.7102 - accuracy: 0.7476 - val_loss: 0.9962 - val_accuracy: 0.6784\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6984 - accuracy: 0.7532 - val_loss: 0.9480 - val_accuracy: 0.6864\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6993 - accuracy: 0.7507 - val_loss: 0.9393 - val_accuracy: 0.6886\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6814 - accuracy: 0.7593 - val_loss: 0.9742 - val_accuracy: 0.6832\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6790 - accuracy: 0.7588 - val_loss: 0.9794 - val_accuracy: 0.6840\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6780 - accuracy: 0.7609 - val_loss: 0.9484 - val_accuracy: 0.6902\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6610 - accuracy: 0.7649 - val_loss: 1.0118 - val_accuracy: 0.6778\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.6616 - accuracy: 0.7660 - val_loss: 0.9668 - val_accuracy: 0.6920\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6598 - accuracy: 0.7668 - val_loss: 0.9782 - val_accuracy: 0.6878\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6520 - accuracy: 0.7702 - val_loss: 0.9799 - val_accuracy: 0.6908\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6529 - accuracy: 0.7691 - val_loss: 0.9985 - val_accuracy: 0.6896\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6415 - accuracy: 0.7718 - val_loss: 0.9987 - val_accuracy: 0.6820\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6426 - accuracy: 0.7716 - val_loss: 1.0002 - val_accuracy: 0.6936\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6253 - accuracy: 0.7790 - val_loss: 0.9834 - val_accuracy: 0.6936\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6202 - accuracy: 0.7806 - val_loss: 0.9807 - val_accuracy: 0.6934\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6172 - accuracy: 0.7808 - val_loss: 1.0021 - val_accuracy: 0.6854\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6221 - accuracy: 0.7795 - val_loss: 1.0136 - val_accuracy: 0.6830\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6132 - accuracy: 0.7820 - val_loss: 1.0335 - val_accuracy: 0.6894\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6037 - accuracy: 0.7857 - val_loss: 0.9995 - val_accuracy: 0.6946\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.6032 - accuracy: 0.7846 - val_loss: 0.9898 - val_accuracy: 0.6906\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 15s 85ms/step - loss: 0.5943 - accuracy: 0.7880 - val_loss: 1.0063 - val_accuracy: 0.6878\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.6101 - accuracy: 0.7840 - val_loss: 1.0008 - val_accuracy: 0.6872\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5921 - accuracy: 0.7888 - val_loss: 0.9962 - val_accuracy: 0.6790\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5879 - accuracy: 0.7909 - val_loss: 1.0161 - val_accuracy: 0.6922\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 15s 85ms/step - loss: 0.5894 - accuracy: 0.7902 - val_loss: 1.0136 - val_accuracy: 0.6920\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5854 - accuracy: 0.7923 - val_loss: 1.0176 - val_accuracy: 0.6844\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5724 - accuracy: 0.7976 - val_loss: 1.0054 - val_accuracy: 0.6878\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5855 - accuracy: 0.7947 - val_loss: 1.0090 - val_accuracy: 0.6898\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5754 - accuracy: 0.7961 - val_loss: 1.0084 - val_accuracy: 0.6938\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5745 - accuracy: 0.7947 - val_loss: 1.0392 - val_accuracy: 0.6922\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5714 - accuracy: 0.7953 - val_loss: 1.0446 - val_accuracy: 0.6872\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5662 - accuracy: 0.8000 - val_loss: 1.0265 - val_accuracy: 0.6900\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5566 - accuracy: 0.8030 - val_loss: 1.0169 - val_accuracy: 0.6932\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5616 - accuracy: 0.8020 - val_loss: 1.0067 - val_accuracy: 0.6864\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5586 - accuracy: 0.8027 - val_loss: 1.0459 - val_accuracy: 0.6818\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5565 - accuracy: 0.8024 - val_loss: 1.0323 - val_accuracy: 0.6868\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5562 - accuracy: 0.8000 - val_loss: 1.0687 - val_accuracy: 0.6812\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5686 - accuracy: 0.8002 - val_loss: 1.0097 - val_accuracy: 0.6894\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5522 - accuracy: 0.8036 - val_loss: 1.0360 - val_accuracy: 0.6918\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5574 - accuracy: 0.8043 - val_loss: 1.0169 - val_accuracy: 0.6908\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5450 - accuracy: 0.8087 - val_loss: 1.0430 - val_accuracy: 0.6930\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5523 - accuracy: 0.8043 - val_loss: 1.0414 - val_accuracy: 0.6882\n",
      "Epoch 72/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5407 - accuracy: 0.8094 - val_loss: 1.0278 - val_accuracy: 0.6962\n",
      "Epoch 73/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5389 - accuracy: 0.8078 - val_loss: 1.0610 - val_accuracy: 0.6876\n",
      "Epoch 74/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5389 - accuracy: 0.8115 - val_loss: 1.0817 - val_accuracy: 0.6820\n",
      "Epoch 75/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5362 - accuracy: 0.8117 - val_loss: 1.0767 - val_accuracy: 0.6954\n",
      "Epoch 76/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5307 - accuracy: 0.8124 - val_loss: 1.0252 - val_accuracy: 0.6986\n",
      "Epoch 77/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5235 - accuracy: 0.8147 - val_loss: 1.0224 - val_accuracy: 0.6888\n",
      "Epoch 78/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5274 - accuracy: 0.8120 - val_loss: 1.0544 - val_accuracy: 0.6854\n",
      "Epoch 79/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5287 - accuracy: 0.8117 - val_loss: 1.0355 - val_accuracy: 0.6882\n",
      "Epoch 80/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5264 - accuracy: 0.8134 - val_loss: 1.0652 - val_accuracy: 0.6946\n",
      "Epoch 81/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5266 - accuracy: 0.8115 - val_loss: 1.0599 - val_accuracy: 0.6890\n",
      "Epoch 82/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5169 - accuracy: 0.8179 - val_loss: 1.0786 - val_accuracy: 0.6860\n",
      "Epoch 83/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5275 - accuracy: 0.8133 - val_loss: 1.0465 - val_accuracy: 0.6896\n",
      "Epoch 84/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5211 - accuracy: 0.8163 - val_loss: 1.0576 - val_accuracy: 0.6902\n",
      "Epoch 85/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5158 - accuracy: 0.8179 - val_loss: 1.0744 - val_accuracy: 0.6940\n",
      "Epoch 86/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5099 - accuracy: 0.8210 - val_loss: 1.0564 - val_accuracy: 0.6888\n",
      "Epoch 87/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5228 - accuracy: 0.8157 - val_loss: 1.0854 - val_accuracy: 0.6896\n",
      "Epoch 88/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5139 - accuracy: 0.8189 - val_loss: 1.0635 - val_accuracy: 0.6930\n",
      "Epoch 89/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5132 - accuracy: 0.8187 - val_loss: 1.0610 - val_accuracy: 0.6926\n",
      "Epoch 90/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.5130 - accuracy: 0.8180 - val_loss: 1.0519 - val_accuracy: 0.6868\n",
      "Epoch 91/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5039 - accuracy: 0.8220 - val_loss: 1.0594 - val_accuracy: 0.7012\n",
      "Epoch 92/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5150 - accuracy: 0.8193 - val_loss: 1.0714 - val_accuracy: 0.6956\n",
      "Epoch 93/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5126 - accuracy: 0.8189 - val_loss: 1.0530 - val_accuracy: 0.6978\n",
      "Epoch 94/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5110 - accuracy: 0.8213 - val_loss: 1.0460 - val_accuracy: 0.6890\n",
      "Epoch 95/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5029 - accuracy: 0.8216 - val_loss: 1.0457 - val_accuracy: 0.6906\n",
      "Epoch 96/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.5046 - accuracy: 0.8236 - val_loss: 1.0678 - val_accuracy: 0.6856\n",
      "Epoch 97/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.4950 - accuracy: 0.8262 - val_loss: 1.0560 - val_accuracy: 0.6902\n",
      "Epoch 98/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.4984 - accuracy: 0.8242 - val_loss: 1.0925 - val_accuracy: 0.6944\n",
      "Epoch 99/100\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.4991 - accuracy: 0.8234 - val_loss: 1.0643 - val_accuracy: 0.6904\n",
      "Epoch 100/100\n",
      "176/176 [==============================] - 15s 86ms/step - loss: 0.4999 - accuracy: 0.8242 - val_loss: 1.0880 - val_accuracy: 0.6954\n"
     ]
    }
   ],
   "source": [
    "# Additional training\n",
    "history = model.fit(x_train, y_train_fixed, batch_size=batch_size, epochs=100, validation_split=validation_split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
